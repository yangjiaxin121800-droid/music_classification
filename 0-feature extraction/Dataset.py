from torch.utils.data import Dataset
from sklearn.model_selection import train_test_split
import torch
import random
import os
import glob
import numpy as np


class MusicDataset(Dataset):
    def __init__(self, features, labels, transform=None):
        self.features = features
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        feature = self.features[idx]
        label = self.labels[idx]

        feature = torch.FloatTensor(feature).unsqueeze(0)  
        label = torch.LongTensor([label])[0]
        
        if self.transform:
            feature = self.transform(feature)
        
        return feature, label
    
    
class AudioTransform:
    def __init__(self, noise_factor=0.005, time_shift_factor=0.1):
        self.noise_factor = noise_factor
        self.time_shift_factor = time_shift_factor
    
    def __call__(self, x):
        # add noise
        if random.random() > 0.5:
            noise = torch.randn_like(x) * self.noise_factor
            x = x + noise
        
        # add offset
        if random.random() > 0.5:
            shift = int(x.shape[-1] * self.time_shift_factor * (random.random() - 0.5))
            if shift != 0:
                if shift > 0:
                    x = torch.cat([x[..., shift:], torch.zeros_like(x[..., :shift])], dim=-1)
                else:
                    x = torch.cat([torch.zeros_like(x[..., :abs(shift)]), x[..., :shift]], dim=-1)
        
        return x
    

def create_data_splits(features, labels, test_size=0.2, val_size=0.1, random_state=42):
    """
    default train: val: test = 7: 1: 2
    """

    X_temp, X_test, y_temp, y_test = train_test_split(
        features, labels, test_size=test_size, 
        random_state=random_state, stratify=labels
    )

    val_size_adjusted = val_size / (1 - test_size)
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=val_size_adjusted, 
        random_state=random_state, stratify=y_temp
    )

    print("Datasets created")
    print(f"  training set: {np.bincount(y_train)}")
    print(f"validation set: {np.bincount(y_val)}")
    print(f"      test set: {np.bincount(y_test)}")
    
    return X_train, X_val, X_test, y_train, y_val, y_test

def load_all_features(path):
    """
    This function was generated by claude
    """
    
    feature_files = glob.glob(os.path.join(path, 'features_*.npz'))
    if not feature_files:
        print("Features not exist")
        return None, None, None
    
    all_features = []
    all_labels = []
    all_track_ids = []
    
    for file in feature_files:
        print(f"loading: {file}")
        data = np.load(file)
        all_features.append(data['features'])
        all_labels.append(data['labels'])
        all_track_ids.append(data['track_ids'])

    features = np.concatenate(all_features, axis=0)
    labels = np.concatenate(all_labels, axis=0)
    track_ids = np.concatenate(all_track_ids, axis=0)
    
    print(f"Features file loaded successfully")
    
    return features, labels, track_ids


if __name__ == "__main__":
    FEATURE_PATH = 'features'
    features, labels, track_ids = load_all_features(FEATURE_PATH)
    
    if features is not None:
        X_train, X_val, X_test, y_train, y_val, y_test = create_data_splits(features, labels)
        
        # data augmentation for training
        train_transform = AudioTransform()  
        
        train_dataset = MusicDataset(X_train, y_train, transform=train_transform)
        val_dataset = MusicDataset(X_val, y_val, transform=None)
        test_dataset = MusicDataset(X_test, y_test, transform=None)
        
        print("Dataset created")
        
    else:
        print("No features loaded.")
    